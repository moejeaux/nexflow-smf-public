module.exports=[79963,e=>{"use strict";let t=(0,e.i(50377).createLogger)({component:"OpsAlerting"}),r="production",n="NexFlow",a=new Map;async function o(e){let a=process.env.SLACK_WEBHOOK_URL||process.env.SLACK_OPS_WEBHOOK_URL;if(!a)return t.debug({alertTitle:e.title},"Slack webhook not configured, skipping"),!1;let o=function(e){switch(e){case"critical":return"üö®";case"warning":return"‚ö†Ô∏è";case"info":return"‚ÑπÔ∏è"}}(e.severity),i=function(e){switch(e){case"critical":return"#dc3545";case"warning":return"#ffc107";case"info":return"#17a2b8"}}(e.severity),s=[{type:"header",text:{type:"plain_text",text:`${o} ${e.title}`,emoji:!0}},{type:"section",text:{type:"mrkdwn",text:e.description}},{type:"section",fields:[{type:"mrkdwn",text:`*Severity:* ${e.severity.toUpperCase()}`},{type:"mrkdwn",text:`*Source:* ${e.source}`},{type:"mrkdwn",text:`*Environment:* ${r}`},{type:"mrkdwn",text:`*Time:* ${new Date().toISOString()}`}]}];if(e.context&&Object.keys(e.context).length>0){let t=Object.entries(e.context).slice(0,6).map(([e,t])=>{var r;return{type:"mrkdwn",text:`*${e}:* ${null==(r=t)?"N/A":"object"==typeof r?JSON.stringify(r).slice(0,100):String(r).slice(0,100)}`}});s.push({type:"section",fields:t})}e.runbookUrl&&s.push({type:"actions",elements:[{type:"button",text:{type:"plain_text",text:"üìñ View Runbook",emoji:!0},url:e.runbookUrl,style:"primary"}]}),s.push({type:"divider"}),s.push({type:"context",elements:[{type:"mrkdwn",text:`${n} Operations ‚Ä¢ Dedup Key: \`${e.dedupKey}\``}]});try{let r=await fetch(a,{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({text:`[${e.severity.toUpperCase()}] ${e.title}`,blocks:s,attachments:[{color:i}]})});if(!r.ok){let e=await r.text().catch(()=>"");return t.error({status:r.status,body:e},"Failed to send Slack alert"),!1}return t.info({dedupKey:e.dedupKey,title:e.title},"Slack alert sent"),!0}catch(r){return t.error({error:r,dedupKey:e.dedupKey},"Error sending Slack alert"),!1}}async function i(e){let a=process.env.PAGERDUTY_ROUTING_KEY||process.env.PAGERDUTY_INTEGRATION_KEY;if(!a)return t.debug({alertTitle:e.title},"PagerDuty routing key not configured, skipping"),!1;if("info"===e.severity)return t.debug({dedupKey:e.dedupKey},"Skipping info alert for PagerDuty"),!1;let o={routing_key:a,event_action:"trigger",dedup_key:e.dedupKey,payload:{summary:`[${n}] ${e.title}`,source:e.source,severity:function(e){switch(e){case"critical":return"critical";case"warning":return"warning";case"info":return"info"}}(e.severity),timestamp:new Date().toISOString(),component:e.source,group:n,class:"cron-job-failure",custom_details:{description:e.description,environment:r,...e.context}},links:e.runbookUrl?[{href:e.runbookUrl,text:"Runbook"}]:void 0};try{let r=await fetch("https://events.pagerduty.com/v2/enqueue",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify(o)});if(!r.ok){let e=await r.text().catch(()=>"");return t.error({status:r.status,body:e},"Failed to send PagerDuty alert"),!1}let n=await r.json().catch(()=>({}));return t.info({dedupKey:e.dedupKey,title:e.title,pdDedupKey:n.dedup_key},"PagerDuty alert sent"),!0}catch(r){return t.error({error:r,dedupKey:e.dedupKey},"Error sending PagerDuty alert"),!1}}async function s(e){let r=process.env.PAGERDUTY_ROUTING_KEY||process.env.PAGERDUTY_INTEGRATION_KEY;if(!r)return!1;try{let n=await fetch("https://events.pagerduty.com/v2/enqueue",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({routing_key:r,event_action:"resolve",dedup_key:e})});if(!n.ok)return t.error({status:n.status},"Failed to resolve PagerDuty alert"),!1;return t.info({dedupKey:e},"PagerDuty alert resolved"),!0}catch(r){return t.error({error:r,dedupKey:e},"Error resolving PagerDuty alert"),!1}}async function u(e){let r=a.get(e.dedupKey);if(r&&Date.now()-r<3e5)return t.debug({dedupKey:e.dedupKey},"Alert in cooldown, skipping"),{slack:!1,pagerduty:!1};if(a.set(e.dedupKey,Date.now()),a.size>1e3){let e=Date.now()-6e5;for(let[t,r]of Array.from(a.entries()))r<e&&a.delete(t)}let n=e.channel||"all",s={slack:!1,pagerduty:!1};return("slack"===n||"all"===n)&&(s.slack=await o(e)),("pagerduty"===n||"all"===n)&&(s.pagerduty=await i(e)),s}async function c(e){var r;let n,{jobId:a,consecutiveFailures:o,lastError:i,lastFailureAt:s,runId:c}=e;if(o>=5)n="critical";else{if(!(o>=3))return void t.debug({jobId:a,consecutiveFailures:o,threshold:3},"Below alert threshold");n="warning"}let l=e.jobName||a;await u({dedupKey:`cron-failure:${a}`,title:`Cron Job Failing: ${l}`,description:o>=5?`üö® *CRITICAL*: Job \`${a}\` has failed ${o} consecutive times and requires immediate attention.`:`‚ö†Ô∏è Job \`${a}\` has failed ${o} consecutive times.`,severity:n,source:`cron-job:${a}`,context:{"Job ID":a,"Consecutive Failures":o,"Last Error":i?(r=i).length<=200?r:r.slice(0,197)+"...":"N/A","Last Failure":s?s.toISOString():"N/A","Run ID":c||"N/A"},runbookUrl:process.env.CRON_RUNBOOK_URL})}async function l(e,t){await u({dedupKey:`cron-recovery:${e}:${Date.now()}`,title:`Cron Job Recovered: ${t||e}`,description:`‚úÖ Job \`${e}\` has recovered and is running successfully.`,severity:"info",source:`cron-job:${e}`,channel:"slack"}),await s(`cron-failure:${e}`)}e.s(["alertCronJobFailure",()=>c,"alertCronJobRecovered",()=>l])},7484,e=>e.a(async(t,r)=>{try{var n=e.i(89171),a=e.i(50377),o=e.i(36080),i=e.i(34006),s=e.i(79963),u=t([o]);[o]=u.then?(await u)():u;let l=(0,a.createLogger)({component:"CronJobWrapper"});function c(e,t){return async r=>{let a,u,c,d,p=crypto.randomUUID(),f=Date.now(),g=process.env.CRON_SECRET;if(g&&r.headers.get("authorization")!==`Bearer ${g}`)return l.warn({jobId:t.jobId,requestId:p},"Unauthorized cron request"),n.NextResponse.json({error:"Unauthorized"},{status:401});if(t.enabledEnvVar){let e=process.env[t.enabledEnvVar];if("true"!==e)return l.info({jobId:t.jobId,requestId:p},`Skipping - disabled via ${t.enabledEnvVar}`),n.NextResponse.json({ok:!0,skipped:!0,reason:`Disabled via ${t.enabledEnvVar}`})}try{let e=await (0,o.getJobConfig)(t.jobId);if(e&&!e.enabled)return l.info({jobId:t.jobId,requestId:p},"Skipping - disabled in config"),n.NextResponse.json({ok:!0,skipped:!0,reason:"Disabled in job configuration"})}catch(e){l.warn({jobId:t.jobId,requestId:p,error:e},"Failed to check job config")}if(!t.skipRateLimit)try{let e=await (0,i.rateLimitCronJob)(t.jobId,t.minInterval);if(!e.allowed)return l.warn({jobId:t.jobId,requestId:p},"Rate limited - too soon since last run"),n.NextResponse.json({ok:!1,error:"Rate limited",retryAfter:Math.ceil((e.resetAt-Date.now())/1e3)},{status:429,headers:{"Retry-After":Math.ceil((e.resetAt-Date.now())/1e3).toString()}})}catch(e){l.warn({jobId:t.jobId,requestId:p,error:e},"Rate limit check failed")}let y=r.headers.get("x-trigger-source")||"cron",b=parseInt(r.headers.get("x-attempt-number")||"1",10),m={};new URL(r.url).searchParams.forEach((e,t)=>{m[t]=e});try{a=(await (0,o.createJobRun)({jobId:t.jobId,triggerSource:y,attemptNumber:b,inputParams:Object.keys(m).length>0?m:void 0,metadata:{requestId:p,userAgent:r.headers.get("user-agent")}})).id}catch(e){l.warn({jobId:t.jobId,requestId:p,error:e},"Failed to create job run record")}let w={runId:a||p,jobId:t.jobId,requestId:p,attemptNumber:b,triggerSource:y,startTime:f};l.info({jobId:t.jobId,runId:a,requestId:p,triggerSource:y,attemptNumber:b,inputParams:m},"Starting cron job");let _=t.timeout||6e4,R="completed";try{(u=await Promise.race([e(r,w),new Promise((e,t)=>setTimeout(()=>t(Error("Job timeout")),_))])).ok||(R="failed",c=u.error||"Job returned ok: false")}catch(e){R=e instanceof Error&&"Job timeout"===e.message?"timeout":"failed",c=e instanceof Error?e.message:"Unknown error",d=e instanceof Error?e.stack:void 0,l.error({jobId:t.jobId,runId:a,requestId:p,status:R,error:c},"Cron job failed"),u={ok:!1,error:c,status:R}}let h=Date.now()-f;if(a)try{await (0,o.completeJobRun)({runId:a,status:R,outputSummary:function(e){if(JSON.stringify(e).length<=1e4)return e;let t={...e};for(let[e,r]of Object.entries(t))"string"==typeof r&&r.length>500?t[e]=r.substring(0,500)+"... (truncated)":Array.isArray(r)&&r.length>10&&(t[e]=[...r.slice(0,10),`... (${r.length-10} more)`]);return t}(u),errorMessage:c,errorStack:d})}catch(e){l.warn({jobId:t.jobId,runId:a,error:e},"Failed to complete job run record")}if("completed"!==R)try{let e=(await (0,o.getFailingJobs)(3)).find(e=>e.job_id===t.jobId);e&&(l.error({jobId:t.jobId,consecutiveFailures:e.consecutive_failures,lastFailure:e.last_failure_at},`Job has ${e.consecutive_failures} consecutive failures - needs attention`),await (0,s.alertCronJobFailure)({jobId:t.jobId,consecutiveFailures:e.consecutive_failures,lastError:c,lastFailureAt:e.last_failure_at?new Date(e.last_failure_at):void 0,runId:a}))}catch(e){l.warn({jobId:t.jobId,error:e},"Failed to check failing jobs")}else try{let e=await (0,o.getJobConfig)(t.jobId);e&&e.consecutive_failures&&e.consecutive_failures>=3&&await (0,s.alertCronJobRecovered)(t.jobId)}catch(e){l.debug({jobId:t.jobId,error:e},"Could not check for recovery notification")}return l.info({jobId:t.jobId,runId:a,requestId:p,status:R,durationMs:h,ok:u.ok},"Cron job completed"),n.NextResponse.json({...u,_meta:{runId:a,requestId:p,durationMs:h,status:R}},{status:u.ok?200:500})}}e.s(["withCronJobTracking",()=>c]),r()}catch(e){r(e)}},!1),34006,e=>{"use strict";var t=e.i(89171);let r=(0,e.i(50377).createLogger)({component:"RateLimitStore"});class n{store=new Map;cleanupInterval=null;constructor(){"undefined"!=typeof setInterval&&(this.cleanupInterval=setInterval(()=>this.cleanup(),3e5))}cleanup(){let e=Date.now(),t=[];this.store.forEach((r,n)=>{r.resetAt<e&&t.push(n)}),t.forEach(e=>this.store.delete(e))}async get(e){let t=this.store.get(e);return!t||t.resetAt<Date.now()?null:t}async set(e,t){this.store.set(e,t)}async increment(e,t){let r=Date.now(),n=this.store.get(e);if(!n||n.resetAt<r){let n={count:1,resetAt:r+t};return this.store.set(e,n),n}return n.count++,this.store.set(e,n),n}}class a{redis;constructor(e){this.redis=e}async get(e){try{let t=await this.redis.get(`ratelimit:${e}`);if(!t)return null;let r="string"==typeof t?JSON.parse(t):t;if(r.resetAt<Date.now())return null;return r}catch(t){return r.error({error:t,key:e},"Upstash Redis GET failed"),null}}async set(e,t){try{let r=Math.max(t.resetAt-Date.now(),1e3),n=Math.ceil(r/1e3);await this.redis.set(`ratelimit:${e}`,JSON.stringify(t),{ex:n})}catch(t){r.error({error:t,key:e},"Upstash Redis SET failed")}}async increment(e,t){try{let r=`ratelimit:${e}`,n=Date.now(),a=await this.redis.get(r),o=1,i=n+t;if(a){let e="string"==typeof a?JSON.parse(a):a;e.resetAt>n&&(o=e.count+1,i=e.resetAt)}let s={count:o,resetAt:i},u=i-n,c=Math.ceil(u/1e3);return await this.redis.set(r,JSON.stringify(s),{ex:c}),s}catch(n){return r.error({error:n,key:e},"Upstash Redis INCR failed"),{count:1,resetAt:Date.now()+t}}}}let o=null;async function i(){if(o)return o;let t=process.env.UPSTASH_REDIS_REST_URL,i=process.env.UPSTASH_REDIS_REST_TOKEN;if(t&&i)try{let{Redis:n}=await e.A(2759),s=new n({url:t,token:i});return await s.ping(),r.info("Rate limit store using Upstash Redis"),o=new a(s)}catch(e){r.warn({error:e},"Upstash Redis connection failed, falling back to in-memory")}let s=process.env.REDIS_URL;if(s)try{let{Redis:t}=await e.A(6538),n=new t(s,{maxRetriesPerRequest:3,enableReadyCheck:!0,connectTimeout:5e3,lazyConnect:!0});return await n.connect(),r.info("Rate limit store using Redis (ioredis)"),o={async get(e){let t=await n.get(`ratelimit:${e}`);if(!t)return null;let r=JSON.parse(t);return r.resetAt<Date.now()?null:r},async set(e,t){let r=Math.max(t.resetAt-Date.now(),1e3);await n.set(`ratelimit:${e}`,JSON.stringify(t),"PX",r)},async increment(e,t){let r=Date.now(),a=`ratelimit:${e}`,o=await n.get(a),i=1,s=r+t;if(o){let e=JSON.parse(o);e.resetAt>r&&(i=e.count+1,s=e.resetAt)}let u={count:i,resetAt:s},c=s-r;return await n.set(a,JSON.stringify(u),"PX",c),u}}}catch(e){r.warn({error:e},"Redis connection failed, falling back to in-memory")}return r.info("Rate limit store using in-memory (non-distributed)"),o=new n}let s=36e5,u=1e3,c=6e4,l=100,d=36e5,p=1e3,f=6e4,g=1,y={requests:new Map,blocked:new Map,latencies:new Map,lastReset:Date.now()};function b(e,t){if(0===e.length)return 0;let r=Math.ceil(e.length*t)-1;return e[Math.max(0,Math.min(r,e.length-1))]}function m(){let e={},t=0,r=0;for(let n of new Set([...y.requests.keys(),...y.blocked.keys()])){let a=y.requests.get(n)||0,o=y.blocked.get(n)||0,i=y.latencies.get(n)||[];t+=a,r+=o;let s=[...i].sort((e,t)=>e-t);e[n]={total:a,blocked:o,blockRate:a>0?(o/a*100).toFixed(2)+"%":"0%",latency:{p50:Math.round(b(s,.5)),p95:Math.round(b(s,.95)),p99:Math.round(b(s,.99))}}}return{byType:e,totals:{requests:t,blocked:r,blockRate:t>0?(r/t*100).toFixed(2)+"%":"0%"},lastReset:new Date(y.lastReset).toISOString()}}function w(e){return e.ip||e.headers.get("x-forwarded-for")?.split(",")[0]?.trim()||e.headers.get("x-real-ip")||"unknown"}async function _(e,t,r){var n;let a,o,i=Date.now(),s=await e.increment(t.identifier,t.windowMs),u=s.count<=t.maxRequests,c=Math.max(0,t.maxRequests-s.count);return r&&(n=Date.now()-i,(a=Date.now())-y.lastReset>36e5&&(y.requests.clear(),y.blocked.clear(),y.latencies.clear(),y.lastReset=a),y.requests.set(r,(y.requests.get(r)||0)+1),u||y.blocked.set(r,(y.blocked.get(r)||0)+1),(o=y.latencies.get(r))||(o=[],y.latencies.set(r,o)),o.push(n),o.length>100&&o.shift()),{allowed:u,remaining:c,resetAt:s.resetAt,limit:t.maxRequests}}async function R(e,t){let r,n=(r=e.headers.get("authorization"))?r.startsWith("Bearer ")?r.substring(7).trim():r.trim():null;return n?_(await i(),{windowMs:d,maxRequests:t||p,identifier:`api_key:${n.substring(0,16)}`},"api_key"):null}async function h(e,t,r){let n=await i(),a=w(e);return _(n,{windowMs:c,maxRequests:r||l,identifier:`endpoint:${t}:${a}`},`endpoint:${t}`)}async function E(e,t){let r=await i(),n=w(e);return _(r,{windowMs:s,maxRequests:t||u,identifier:`global:${n}`},"global")}async function j(e,t){return _(await i(),{windowMs:t||f,maxRequests:g,identifier:`cron:${e}`},`cron:${e}`)}function S(e,t){return e.headers.set("X-RateLimit-Limit",t.limit.toString()),e.headers.set("X-RateLimit-Remaining",t.remaining.toString()),e.headers.set("X-RateLimit-Reset",new Date(t.resetAt).toISOString()),e}function I(e){let r=new Date(e.resetAt).toISOString(),n=Math.ceil((e.resetAt-Date.now())/1e3),a=t.NextResponse.json({error:"Rate limit exceeded",code:"RATE_LIMIT_EXCEEDED",message:`Too many requests. Limit: ${e.limit} per hour. Try again after ${r}`,retryAfter:n},{status:429});return a.headers.set("Retry-After",n.toString()),S(a,e)}async function D(e,t){let r=[],n=await E(e);r.push(n);let a=await R(e);if(a&&r.push(a),t){let n=await h(e,t);r.push(n)}return 0===r.length?null:r.reduce((e,t)=>t.remaining<e.remaining?t:e)}e.s(["addRateLimitHeaders",()=>S,"createRateLimitResponse",()=>I,"getRateLimitHeaders",()=>D,"getRateLimitMetrics",()=>m,"rateLimitByApiKey",()=>R,"rateLimitCronJob",()=>j],34006)},36080,e=>e.a(async(t,r)=>{try{var n=e.i(24924),a=e.i(50377),o=t([n]);async function i(e){let t=(0,n.getDb)(),r=crypto.randomUUID();return"pool"in t?(await t.query(`INSERT INTO cron_job_runs (id, job_id, status, trigger_source, attempt_number, input_params, metadata)
       VALUES ($1, $2, 'running', $3, $4, $5, $6)
       RETURNING *`,[r,e.jobId,e.triggerSource||"cron",e.attemptNumber||1,e.inputParams?JSON.stringify(e.inputParams):null,e.metadata?JSON.stringify(e.metadata):null])).rows[0]:(t.prepare(`INSERT INTO cron_job_runs (id, job_id, status, trigger_source, attempt_number, input_params, metadata, started_at, created_at)
       VALUES (?, ?, 'running', ?, ?, ?, ?, datetime('now'), datetime('now'))`).run(r,e.jobId,e.triggerSource||"cron",e.attemptNumber||1,e.inputParams?JSON.stringify(e.inputParams):null,e.metadata?JSON.stringify(e.metadata):null),t.prepare("SELECT * FROM cron_job_runs WHERE id = ?").get(r))}async function s(e){let t=(0,n.getDb)();"pool"in t?await t.query(`UPDATE cron_job_runs
       SET status = $1,
           completed_at = now(),
           duration_ms = EXTRACT(EPOCH FROM (now() - started_at)) * 1000,
           output_summary = $2,
           error_message = $3,
           error_stack = $4
       WHERE id = $5`,[e.status,e.outputSummary?JSON.stringify(e.outputSummary):null,e.errorMessage||null,e.errorStack||null,e.runId]):t.prepare(`UPDATE cron_job_runs
       SET status = ?,
           completed_at = datetime('now'),
           duration_ms = (julianday('now') - julianday(started_at)) * 86400000,
           output_summary = ?,
           error_message = ?,
           error_stack = ?
       WHERE id = ?`).run(e.status,e.outputSummary?JSON.stringify(e.outputSummary):null,e.errorMessage||null,e.errorStack||null,e.runId),await u(e)}async function u(e){let t,r=(0,n.getDb)();if("pool"in r){let n=await r.query("SELECT job_id FROM cron_job_runs WHERE id = $1",[e.runId]);if(0===n.rows.length)return;t=n.rows[0].job_id}else{let n=r.prepare("SELECT job_id FROM cron_job_runs WHERE id = ?").get(e.runId);if(!n)return;t=n.job_id}"completed"===e.status?"pool"in r?await r.query(`UPDATE cron_job_config
         SET consecutive_failures = 0, last_success_at = now(), updated_at = now()
         WHERE job_id = $1`,[t]):r.prepare(`UPDATE cron_job_config
         SET consecutive_failures = 0, last_success_at = datetime('now'), updated_at = datetime('now')
         WHERE job_id = ?`).run(t):("failed"===e.status||"timeout"===e.status)&&("pool"in r?await r.query(`UPDATE cron_job_config
         SET consecutive_failures = consecutive_failures + 1, last_failure_at = now(), updated_at = now()
         WHERE job_id = $1`,[t]):r.prepare(`UPDATE cron_job_config
         SET consecutive_failures = consecutive_failures + 1, last_failure_at = datetime('now'), updated_at = datetime('now')
         WHERE job_id = ?`).run(t))}async function c(e,t=20){let r=(0,n.getDb)();return"pool"in r?(await r.query(`SELECT * FROM cron_job_runs
       WHERE job_id = $1
       ORDER BY started_at DESC
       LIMIT $2`,[e,t])).rows:r.prepare(`SELECT * FROM cron_job_runs
       WHERE job_id = ?
       ORDER BY started_at DESC
       LIMIT ?`).all(e,t)}async function l(e=50){let t=(0,n.getDb)();return"pool"in t?(await t.query(`SELECT * FROM cron_job_runs
       ORDER BY started_at DESC
       LIMIT $1`,[e])).rows:t.prepare(`SELECT * FROM cron_job_runs
       ORDER BY started_at DESC
       LIMIT ?`).all(e)}async function d(e){let t=(0,n.getDb)();return"pool"in t?(await t.query("SELECT * FROM cron_job_config WHERE job_id = $1",[e])).rows[0]||null:t.prepare("SELECT * FROM cron_job_config WHERE job_id = ?").get(e)}async function p(){let e=(0,n.getDb)();return"pool"in e?(await e.query("SELECT * FROM cron_job_config ORDER BY job_id")).rows:e.prepare("SELECT * FROM cron_job_config ORDER BY job_id").all()}async function f(e=3){let t=(0,n.getDb)();return"pool"in t?(await t.query(`SELECT * FROM cron_job_config
       WHERE consecutive_failures >= $1 AND alert_on_failure = true
       ORDER BY consecutive_failures DESC`,[e])).rows:t.prepare(`SELECT * FROM cron_job_config
       WHERE consecutive_failures >= ? AND alert_on_failure = 1
       ORDER BY consecutive_failures DESC`).all(e)}[n]=o.then?(await o)():o,(0,a.createLogger)({component:"CronJobDb"}),e.s(["completeJobRun",()=>s,"createJobRun",()=>i,"getAllJobConfigs",()=>p,"getAllRecentRuns",()=>l,"getFailingJobs",()=>f,"getJobConfig",()=>d,"getRecentJobRuns",()=>c]),r()}catch(e){r(e)}},!1)];

//# sourceMappingURL=src_99e2e9f0._.js.map