{"version":3,"sources":["../../../src/services/facilitator-metrics-service.ts","../../../src/services/facilitator-volume-service.ts"],"sourcesContent":["// =============================================================================\r\n// FACILITATOR METRICS SERVICE\r\n// =============================================================================\r\n// Service for persisting and managing facilitator path metrics from x402scan\r\n// Uses Supabase/PostgreSQL in production, falls back to JSON files in development\r\n//\r\n// =============================================================================\r\n// RETENTION & COMPACTION PLAN (TODO)\r\n// =============================================================================\r\n// 1. Raw buckets (bucketMinutes < 60):\r\n//    - Keep for 7 days\r\n//    - After 7 days, compact into hourly rollups\r\n//\r\n// 2. Hourly rollups (bucketMinutes = 60):\r\n//    - Keep for 30 days\r\n//    - After 30 days, compact into daily rollups\r\n//\r\n// 3. Daily rollups (bucketMinutes = 1440):\r\n//    - Keep for 90 days\r\n//    - After 90 days, archive or delete\r\n//\r\n// Compaction strategy:\r\n//    - Sum invocations, successCount, failureCount, status buckets\r\n//    - Weighted average for latency percentiles (weight by invocations)\r\n//    - Recalculate errorRate from compacted counts\r\n//\r\n// TODO: Implement compactMetrics() function for scheduled compaction job\r\n// =============================================================================\r\n\r\nimport { createLogger } from '@/lib/logger';\r\nimport {\r\n  type FacilitatorPathMetrics,\r\n  type FacilitatorSummary,\r\n  type FacilitatorPathMetricsTimeframe,\r\n  type FacilitatorMethodMetrics,\r\n} from '@/infra/x402scan/types';\r\nimport { Pool } from 'pg';\r\n\r\nconst logger = createLogger({ component: 'FacilitatorMetricsService' });\r\n\r\n// =============================================================================\r\n// DATABASE CONNECTION\r\n// =============================================================================\r\n\r\nlet pool: Pool | null = null;\r\n\r\nfunction getPool(): Pool | null {\r\n  if (pool) return pool;\r\n  \r\n  const databaseUrl = process.env.DATABASE_URL;\r\n  if (!databaseUrl || !databaseUrl.startsWith('postgresql://')) {\r\n    return null;\r\n  }\r\n  \r\n  pool = new Pool({\r\n    connectionString: databaseUrl,\r\n    max: 5,\r\n    idleTimeoutMillis: 30000,\r\n    connectionTimeoutMillis: 5000,\r\n  });\r\n  \r\n  return pool;\r\n}\r\n\r\n// =============================================================================\r\n// DATABASE STORAGE FUNCTIONS\r\n// =============================================================================\r\n\r\n/**\r\n * Upsert facilitator path metrics to the database\r\n */\r\nasync function upsertMetricsToDb(metrics: FacilitatorPathMetrics[]): Promise<void> {\r\n  const db = getPool();\r\n  if (!db || metrics.length === 0) return;\r\n\r\n  const client = await db.connect();\r\n  try {\r\n    await client.query('BEGIN');\r\n\r\n    for (const m of metrics) {\r\n      await client.query(`\r\n        INSERT INTO smf_facilitator_metrics (\r\n          kind, facilitator_id, resource_url, server_id, network,\r\n          timeframe, bucket_minutes, time_bucket_start, time_bucket_end,\r\n          invocations, success_count, failure_count,\r\n          count_2xx, count_3xx, count_4xx, count_5xx,\r\n          error_rate, avg_latency_ms, p50_latency_ms, p90_latency_ms, p95_latency_ms, p99_latency_ms,\r\n          methods, fetched_at, updated_at\r\n        ) VALUES (\r\n          $1, $2, $3, $4, $5,\r\n          $6, $7, $8, $9,\r\n          $10, $11, $12,\r\n          $13, $14, $15, $16,\r\n          $17, $18, $19, $20, $21, $22,\r\n          $23, $24, NOW()\r\n        )\r\n        ON CONFLICT (facilitator_id, timeframe, time_bucket_start)\r\n        DO UPDATE SET\r\n          kind = EXCLUDED.kind,\r\n          resource_url = EXCLUDED.resource_url,\r\n          server_id = EXCLUDED.server_id,\r\n          network = EXCLUDED.network,\r\n          bucket_minutes = EXCLUDED.bucket_minutes,\r\n          time_bucket_end = EXCLUDED.time_bucket_end,\r\n          invocations = EXCLUDED.invocations,\r\n          success_count = EXCLUDED.success_count,\r\n          failure_count = EXCLUDED.failure_count,\r\n          count_2xx = EXCLUDED.count_2xx,\r\n          count_3xx = EXCLUDED.count_3xx,\r\n          count_4xx = EXCLUDED.count_4xx,\r\n          count_5xx = EXCLUDED.count_5xx,\r\n          error_rate = EXCLUDED.error_rate,\r\n          avg_latency_ms = EXCLUDED.avg_latency_ms,\r\n          p50_latency_ms = EXCLUDED.p50_latency_ms,\r\n          p90_latency_ms = EXCLUDED.p90_latency_ms,\r\n          p95_latency_ms = EXCLUDED.p95_latency_ms,\r\n          p99_latency_ms = EXCLUDED.p99_latency_ms,\r\n          methods = EXCLUDED.methods,\r\n          fetched_at = EXCLUDED.fetched_at,\r\n          updated_at = NOW()\r\n      `, [\r\n        m.kind,\r\n        m.facilitatorId,\r\n        m.resourceUrl || null,\r\n        m.serverId || null,\r\n        m.network || null,\r\n        m.timeframe,\r\n        m.bucketMinutes,\r\n        m.timeBucketStart,\r\n        m.timeBucketEnd,\r\n        m.invocations,\r\n        m.successCount,\r\n        m.failureCount,\r\n        m.count2xx,\r\n        m.count3xx,\r\n        m.count4xx,\r\n        m.count5xx,\r\n        m.errorRate,\r\n        m.avgLatencyMs || null,\r\n        m.p50LatencyMs || null,\r\n        m.p90LatencyMs || null,\r\n        m.p95LatencyMs || null,\r\n        m.p99LatencyMs || null,\r\n        m.methods ? JSON.stringify(m.methods) : null,\r\n        m.fetchedAt,\r\n      ]);\r\n    }\r\n\r\n    await client.query('COMMIT');\r\n    \r\n    logger.info({\r\n      count: metrics.length,\r\n      facilitatorId: metrics[0]?.facilitatorId,\r\n      timeframe: metrics[0]?.timeframe,\r\n      msg: 'Facilitator metrics upserted to database',\r\n    });\r\n  } catch (error) {\r\n    await client.query('ROLLBACK');\r\n    throw error;\r\n  } finally {\r\n    client.release();\r\n  }\r\n}\r\n\r\n/**\r\n * Load metrics from database\r\n */\r\nasync function loadMetricsFromDb(\r\n  facilitatorId?: string,\r\n  timeframe?: FacilitatorPathMetricsTimeframe\r\n): Promise<FacilitatorPathMetrics[]> {\r\n  const db = getPool();\r\n  if (!db) return [];\r\n\r\n  let query = `\r\n    SELECT * FROM smf_facilitator_metrics\r\n    WHERE fetched_at > NOW() - INTERVAL '30 days'\r\n  `;\r\n  const params: any[] = [];\r\n  let paramIndex = 1;\r\n\r\n  if (facilitatorId) {\r\n    query += ` AND facilitator_id = $${paramIndex}`;\r\n    params.push(facilitatorId);\r\n    paramIndex++;\r\n  }\r\n\r\n  if (timeframe) {\r\n    query += ` AND timeframe = $${paramIndex}`;\r\n    params.push(timeframe);\r\n    paramIndex++;\r\n  }\r\n\r\n  query += ' ORDER BY time_bucket_start DESC LIMIT 1000';\r\n\r\n  const result = await db.query(query, params);\r\n  return result.rows.map(mapDbRowToMetrics);\r\n}\r\n\r\n/**\r\n * Map database row to FacilitatorPathMetrics\r\n */\r\nfunction mapDbRowToMetrics(row: any): FacilitatorPathMetrics {\r\n  return {\r\n    kind: row.kind || 'facilitator-global',\r\n    facilitatorId: row.facilitator_id,\r\n    resourceUrl: row.resource_url || undefined,\r\n    serverId: row.server_id || undefined,\r\n    network: row.network || undefined,\r\n    timeframe: row.timeframe,\r\n    bucketMinutes: row.bucket_minutes,\r\n    timeBucketStart: row.time_bucket_start?.toISOString() || row.time_bucket_start,\r\n    timeBucketEnd: row.time_bucket_end?.toISOString() || row.time_bucket_end,\r\n    invocations: row.invocations,\r\n    successCount: row.success_count,\r\n    failureCount: row.failure_count,\r\n    count2xx: row.count_2xx,\r\n    count3xx: row.count_3xx,\r\n    count4xx: row.count_4xx,\r\n    count5xx: row.count_5xx,\r\n    errorRate: parseFloat(row.error_rate) || 0,\r\n    avgLatencyMs: row.avg_latency_ms ? parseFloat(row.avg_latency_ms) : undefined,\r\n    p50LatencyMs: row.p50_latency_ms ? parseFloat(row.p50_latency_ms) : undefined,\r\n    p90LatencyMs: row.p90_latency_ms ? parseFloat(row.p90_latency_ms) : undefined,\r\n    p95LatencyMs: row.p95_latency_ms ? parseFloat(row.p95_latency_ms) : undefined,\r\n    p99LatencyMs: row.p99_latency_ms ? parseFloat(row.p99_latency_ms) : undefined,\r\n    methods: row.methods || undefined,\r\n    fetchedAt: row.fetched_at?.toISOString() || row.fetched_at,\r\n  };\r\n}\r\n\r\n/**\r\n * Upsert summary to database\r\n */\r\nasync function upsertSummaryToDb(summary: FacilitatorSummary): Promise<void> {\r\n  const db = getPool();\r\n  if (!db) return;\r\n\r\n  // Handle empty timestamps - skip if no valid data\r\n  const dataStart = summary.dataStart && summary.dataStart.length > 0 ? summary.dataStart : null;\r\n  const dataEnd = summary.dataEnd && summary.dataEnd.length > 0 ? summary.dataEnd : null;\r\n  \r\n  // Skip summaries with no actual data\r\n  if (summary.totalInvocations === 0 && !dataStart && !dataEnd) {\r\n    logger.debug({\r\n      facilitatorId: summary.facilitatorId,\r\n      timeframe: summary.timeframe,\r\n      msg: 'Skipping summary with no data',\r\n    });\r\n    return;\r\n  }\r\n\r\n  await db.query(`\r\n    INSERT INTO smf_facilitator_summaries (\r\n      facilitator_id, timeframe,\r\n      total_invocations, total_successes, total_failures, overall_error_rate,\r\n      avg_p50_latency_ms, avg_p90_latency_ms, avg_p99_latency_ms,\r\n      top_methods, data_start, data_end, fetched_at, updated_at\r\n    ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, NOW())\r\n    ON CONFLICT (facilitator_id, timeframe)\r\n    DO UPDATE SET\r\n      total_invocations = EXCLUDED.total_invocations,\r\n      total_successes = EXCLUDED.total_successes,\r\n      total_failures = EXCLUDED.total_failures,\r\n      overall_error_rate = EXCLUDED.overall_error_rate,\r\n      avg_p50_latency_ms = EXCLUDED.avg_p50_latency_ms,\r\n      avg_p90_latency_ms = EXCLUDED.avg_p90_latency_ms,\r\n      avg_p99_latency_ms = EXCLUDED.avg_p99_latency_ms,\r\n      top_methods = EXCLUDED.top_methods,\r\n      data_start = COALESCE(EXCLUDED.data_start, smf_facilitator_summaries.data_start),\r\n      data_end = COALESCE(EXCLUDED.data_end, smf_facilitator_summaries.data_end),\r\n      fetched_at = EXCLUDED.fetched_at,\r\n      updated_at = NOW()\r\n  `, [\r\n    summary.facilitatorId,\r\n    summary.timeframe,\r\n    summary.totalInvocations,\r\n    summary.totalSuccesses,\r\n    summary.totalFailures,\r\n    summary.overallErrorRate,\r\n    summary.avgP50LatencyMs || null,\r\n    summary.avgP90LatencyMs || null,\r\n    summary.avgP99LatencyMs || null,\r\n    JSON.stringify(summary.topMethods),\r\n    dataStart,\r\n    dataEnd,\r\n    summary.fetchedAt,\r\n  ]);\r\n\r\n  logger.info({\r\n    facilitatorId: summary.facilitatorId,\r\n    timeframe: summary.timeframe,\r\n    totalInvocations: summary.totalInvocations,\r\n    msg: 'Facilitator summary upserted to database',\r\n  });\r\n}\r\n\r\n/**\r\n * Load all summaries from database\r\n */\r\nasync function loadSummariesFromDb(): Promise<Record<string, FacilitatorSummary>> {\r\n  const db = getPool();\r\n  if (!db) return {};\r\n\r\n  const result = await db.query(`\r\n    SELECT * FROM smf_facilitator_summaries\r\n    ORDER BY fetched_at DESC\r\n  `);\r\n\r\n  const summaries: Record<string, FacilitatorSummary> = {};\r\n  for (const row of result.rows) {\r\n    const key = `${row.facilitator_id}:${row.timeframe}`;\r\n    summaries[key] = {\r\n      facilitatorId: row.facilitator_id,\r\n      timeframe: row.timeframe,\r\n      totalInvocations: parseInt(row.total_invocations) || 0,\r\n      totalSuccesses: parseInt(row.total_successes) || 0,\r\n      totalFailures: parseInt(row.total_failures) || 0,\r\n      overallErrorRate: parseFloat(row.overall_error_rate) || 0,\r\n      avgP50LatencyMs: row.avg_p50_latency_ms ? parseFloat(row.avg_p50_latency_ms) : undefined,\r\n      avgP90LatencyMs: row.avg_p90_latency_ms ? parseFloat(row.avg_p90_latency_ms) : undefined,\r\n      avgP99LatencyMs: row.avg_p99_latency_ms ? parseFloat(row.avg_p99_latency_ms) : undefined,\r\n      topMethods: row.top_methods || [],\r\n      dataStart: row.data_start?.toISOString() || row.data_start,\r\n      dataEnd: row.data_end?.toISOString() || row.data_end,\r\n      fetchedAt: row.fetched_at?.toISOString() || row.fetched_at,\r\n    };\r\n  }\r\n\r\n  return summaries;\r\n}\r\n\r\n// =============================================================================\r\n// PUBLIC API - Abstracts storage backend\r\n// =============================================================================\r\n\r\n/**\r\n * Check if database is available\r\n */\r\nexport function isDatabaseAvailable(): boolean {\r\n  return getPool() !== null;\r\n}\r\n\r\n/**\r\n * Load all stored metrics\r\n */\r\nexport async function loadAllMetrics(): Promise<FacilitatorPathMetrics[]> {\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      return await loadMetricsFromDb();\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to load metrics from database, returning empty' });\r\n      return [];\r\n    }\r\n  }\r\n  // Fallback: return empty in production if DB not available\r\n  logger.warn({ msg: 'Database not available, returning empty metrics' });\r\n  return [];\r\n}\r\n\r\n/**\r\n * Upsert facilitator path metrics\r\n * Updates existing records or inserts new ones based on (facilitatorId, timeframe, timeBucketStart)\r\n */\r\nexport async function upsertFacilitatorPathMetrics(\r\n  metrics: FacilitatorPathMetrics[]\r\n): Promise<void> {\r\n  if (metrics.length === 0) {\r\n    logger.debug('No metrics to upsert');\r\n    return;\r\n  }\r\n\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      await upsertMetricsToDb(metrics);\r\n      return;\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to upsert metrics to database' });\r\n      throw error;\r\n    }\r\n  }\r\n  \r\n  // In production without DB, log warning\r\n  logger.warn({ \r\n    count: metrics.length, \r\n    msg: 'Database not available, metrics not persisted' \r\n  });\r\n}\r\n\r\n/**\r\n * Load stored summaries\r\n */\r\nexport async function loadAllSummaries(): Promise<Record<string, FacilitatorSummary>> {\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      return await loadSummariesFromDb();\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to load summaries from database' });\r\n      return {};\r\n    }\r\n  }\r\n  return {};\r\n}\r\n\r\n/**\r\n * Upsert facilitator summary\r\n */\r\nexport async function upsertFacilitatorSummary(summary: FacilitatorSummary): Promise<void> {\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      await upsertSummaryToDb(summary);\r\n      return;\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to upsert summary to database' });\r\n      throw error;\r\n    }\r\n  }\r\n  \r\n  logger.warn({ \r\n    facilitatorId: summary.facilitatorId, \r\n    msg: 'Database not available, summary not persisted' \r\n  });\r\n}\r\n\r\n/**\r\n * Upsert multiple facilitator summaries\r\n */\r\nexport async function upsertFacilitatorSummaries(summaries: FacilitatorSummary[]): Promise<void> {\r\n  for (const summary of summaries) {\r\n    await upsertFacilitatorSummary(summary);\r\n  }\r\n}\r\n\r\n// =============================================================================\r\n// QUERY FUNCTIONS\r\n// =============================================================================\r\n\r\n/**\r\n * Get metrics for a specific facilitator\r\n */\r\nexport async function getMetricsForFacilitator(\r\n  facilitatorId: string,\r\n  timeframe?: FacilitatorPathMetricsTimeframe\r\n): Promise<FacilitatorPathMetrics[]> {\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      return await loadMetricsFromDb(facilitatorId, timeframe);\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to get metrics for facilitator' });\r\n      return [];\r\n    }\r\n  }\r\n  return [];\r\n}\r\n\r\n/**\r\n * Get summary for a specific facilitator and timeframe\r\n */\r\nexport async function getSummary(\r\n  facilitatorId: string,\r\n  timeframe: FacilitatorPathMetricsTimeframe\r\n): Promise<FacilitatorSummary | null> {\r\n  const summaries = await loadAllSummaries();\r\n  const key = `${facilitatorId}:${timeframe}`;\r\n  return summaries[key] ?? null;\r\n}\r\n\r\n/**\r\n * Get all summaries for a specific facilitator across all timeframes\r\n */\r\nexport async function getSummariesForFacilitator(\r\n  facilitatorId: string\r\n): Promise<FacilitatorSummary[]> {\r\n  const summaries = await loadAllSummaries();\r\n  return Object.values(summaries).filter((s) => s.facilitatorId === facilitatorId);\r\n}\r\n\r\n/**\r\n * Get latest metrics across all facilitators\r\n */\r\nexport async function getLatestMetrics(\r\n  limit: number = 100\r\n): Promise<FacilitatorPathMetrics[]> {\r\n  const allMetrics = await loadAllMetrics();\r\n  return allMetrics.slice(0, limit);\r\n}\r\n\r\n/**\r\n * Get metrics comparison across facilitators for a timeframe\r\n */\r\nexport async function compareFacilitators(\r\n  facilitatorIds: string[],\r\n  timeframe: FacilitatorPathMetricsTimeframe\r\n): Promise<Map<string, FacilitatorSummary | null>> {\r\n  const summaries = await loadAllSummaries();\r\n  const result = new Map<string, FacilitatorSummary | null>();\r\n\r\n  for (const id of facilitatorIds) {\r\n    const key = `${id}:${timeframe}`;\r\n    result.set(id, summaries[key] ?? null);\r\n  }\r\n\r\n  return result;\r\n}\r\n\r\n// =============================================================================\r\n// CLEANUP\r\n// =============================================================================\r\n\r\n/**\r\n * Clean up old metrics data\r\n */\r\nexport async function cleanupOldMetrics(daysToKeep: number = 30): Promise<number> {\r\n  const db = getPool();\r\n  if (!db) return 0;\r\n\r\n  const result = await db.query(`\r\n    DELETE FROM smf_facilitator_metrics\r\n    WHERE time_bucket_start < NOW() - INTERVAL '${daysToKeep} days'\r\n  `);\r\n\r\n  const removed = result.rowCount || 0;\r\n  if (removed > 0) {\r\n    logger.info({ removed, daysToKeep, msg: 'Old metrics cleaned up from database' });\r\n  }\r\n\r\n  return removed;\r\n}\r\n","// =============================================================================\r\n// FACILITATOR VOLUME SERVICE\r\n// =============================================================================\r\n// Service for persisting and managing facilitator volume/activity metrics from Scattering\r\n// Uses Supabase/PostgreSQL in production, falls back to logging-only in development\r\n//\r\n// =============================================================================\r\n// RETENTION PLAN (TODO)\r\n// =============================================================================\r\n// 1. Current period snapshots (3d):\r\n//    - Keep last 30 snapshots (approx 1 month if pulled daily)\r\n//    - Each snapshot is a full picture of facilitator activity\r\n//\r\n// 2. Historical rollups:\r\n//    - Weekly: Keep 12 weeks of weekly summaries\r\n//    - Monthly: Keep 12 months of monthly summaries\r\n//\r\n// Compaction strategy:\r\n//    - Average volumeUsd3d, txCount3d across period\r\n//    - Track min/max/avg for trend analysis\r\n//    - Keep peak values for market awareness\r\n//\r\n// TODO: Implement weekly/monthly compaction\r\n// =============================================================================\r\n\r\nimport { createLogger } from '@/lib/logger';\r\nimport { type ScatteringFacilitatorMetrics } from '@/infra/scattering/types';\r\nimport { Pool } from 'pg';\r\n\r\nconst logger = createLogger({ component: 'FacilitatorVolumeService' });\r\n\r\n// =============================================================================\r\n// DATABASE CONNECTION\r\n// =============================================================================\r\n\r\nlet pool: Pool | null = null;\r\n\r\nfunction getPool(): Pool | null {\r\n  if (pool) return pool;\r\n  \r\n  const databaseUrl = process.env.DATABASE_URL;\r\n  if (!databaseUrl || !databaseUrl.startsWith('postgresql://')) {\r\n    return null;\r\n  }\r\n  \r\n  pool = new Pool({\r\n    connectionString: databaseUrl,\r\n    max: 5,\r\n    idleTimeoutMillis: 30000,\r\n    connectionTimeoutMillis: 5000,\r\n  });\r\n  \r\n  return pool;\r\n}\r\n\r\n// =============================================================================\r\n// DATABASE STORAGE FUNCTIONS\r\n// =============================================================================\r\n\r\n/**\r\n * Upsert Scattering metrics to database\r\n */\r\nasync function upsertScatteringToDb(metrics: ScatteringFacilitatorMetrics[]): Promise<void> {\r\n  const db = getPool();\r\n  if (!db || metrics.length === 0) return;\r\n\r\n  const client = await db.connect();\r\n  const fetchedAt = new Date().toISOString();\r\n  const snapshotId = crypto.randomUUID ? crypto.randomUUID() : `${Date.now()}-${Math.random().toString(36).slice(2)}`;\r\n  \r\n  try {\r\n    await client.query('BEGIN');\r\n\r\n    for (const m of metrics) {\r\n      // Upsert current metrics\r\n      await client.query(`\r\n        INSERT INTO smf_scattering_metrics (\r\n          facilitator_id, period,\r\n          volume_usd_3d, tx_count_3d, unique_buyers_3d, unique_sellers_3d,\r\n          volume_usd_all_time, chains, volume_change_rate, tx_change_rate,\r\n          fetched_at, updated_at\r\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, NOW())\r\n        ON CONFLICT (facilitator_id, period)\r\n        DO UPDATE SET\r\n          volume_usd_3d = EXCLUDED.volume_usd_3d,\r\n          tx_count_3d = EXCLUDED.tx_count_3d,\r\n          unique_buyers_3d = EXCLUDED.unique_buyers_3d,\r\n          unique_sellers_3d = EXCLUDED.unique_sellers_3d,\r\n          volume_usd_all_time = EXCLUDED.volume_usd_all_time,\r\n          chains = EXCLUDED.chains,\r\n          volume_change_rate = EXCLUDED.volume_change_rate,\r\n          tx_change_rate = EXCLUDED.tx_change_rate,\r\n          fetched_at = EXCLUDED.fetched_at,\r\n          updated_at = NOW()\r\n      `, [\r\n        m.facilitatorId,\r\n        m.period,\r\n        m.volumeUsd3d,\r\n        m.txCount3d,\r\n        m.uniqueBuyers3d,\r\n        m.uniqueSellers3d,\r\n        m.volumeUsdAllTime,\r\n        JSON.stringify(m.chains),\r\n        m.volumeChangeRate ?? null,\r\n        m.txChangeRate ?? null,\r\n        fetchedAt,\r\n      ]);\r\n\r\n      // Insert into history table\r\n      await client.query(`\r\n        INSERT INTO smf_scattering_history (\r\n          snapshot_id, facilitator_id, period,\r\n          volume_usd_3d, tx_count_3d, unique_buyers_3d, unique_sellers_3d,\r\n          volume_usd_all_time, chains, volume_change_rate, tx_change_rate,\r\n          fetched_at\r\n        ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)\r\n      `, [\r\n        snapshotId,\r\n        m.facilitatorId,\r\n        m.period,\r\n        m.volumeUsd3d,\r\n        m.txCount3d,\r\n        m.uniqueBuyers3d,\r\n        m.uniqueSellers3d,\r\n        m.volumeUsdAllTime,\r\n        JSON.stringify(m.chains),\r\n        m.volumeChangeRate ?? null,\r\n        m.txChangeRate ?? null,\r\n        fetchedAt,\r\n      ]);\r\n    }\r\n\r\n    await client.query('COMMIT');\r\n    \r\n    // Log summary\r\n    const totalVolume = metrics.reduce((sum, m) => sum + m.volumeUsd3d, 0);\r\n    const totalTxns = metrics.reduce((sum, m) => sum + m.txCount3d, 0);\r\n\r\n    logger.info({\r\n      facilitatorCount: metrics.length,\r\n      totalVolume3d: `$${formatNumber(totalVolume)}`,\r\n      totalTxns3d: formatNumber(totalTxns),\r\n      msg: 'Scattering metrics upserted to database',\r\n    });\r\n  } catch (error) {\r\n    await client.query('ROLLBACK');\r\n    throw error;\r\n  } finally {\r\n    client.release();\r\n  }\r\n}\r\n\r\n/**\r\n * Load current Scattering metrics from database\r\n */\r\nasync function loadScatteringFromDb(): Promise<Record<string, ScatteringFacilitatorMetrics>> {\r\n  const db = getPool();\r\n  if (!db) return {};\r\n\r\n  const result = await db.query(`\r\n    SELECT * FROM smf_scattering_metrics\r\n    ORDER BY fetched_at DESC\r\n  `);\r\n\r\n  const metrics: Record<string, ScatteringFacilitatorMetrics> = {};\r\n  for (const row of result.rows) {\r\n    metrics[row.facilitator_id] = mapDbRowToScattering(row);\r\n  }\r\n\r\n  return metrics;\r\n}\r\n\r\n/**\r\n * Map database row to ScatteringFacilitatorMetrics\r\n */\r\nfunction mapDbRowToScattering(row: any): ScatteringFacilitatorMetrics {\r\n  return {\r\n    facilitatorId: row.facilitator_id,\r\n    period: row.period || '3d',\r\n    volumeUsd3d: parseFloat(row.volume_usd_3d) || 0,\r\n    txCount3d: parseInt(row.tx_count_3d) || 0,\r\n    uniqueBuyers3d: row.unique_buyers_3d || 0,\r\n    uniqueSellers3d: row.unique_sellers_3d || 0,\r\n    volumeUsdAllTime: parseFloat(row.volume_usd_all_time) || 0,\r\n    chains: row.chains || [],\r\n    volumeChangeRate: row.volume_change_rate ? parseFloat(row.volume_change_rate) : undefined,\r\n    txChangeRate: row.tx_change_rate ? parseFloat(row.tx_change_rate) : undefined,\r\n    fetchedAt: row.fetched_at?.toISOString() || row.fetched_at,\r\n  };\r\n}\r\n\r\n// =============================================================================\r\n// PUBLIC API\r\n// =============================================================================\r\n\r\n/**\r\n * Check if database is available\r\n */\r\nexport function isDatabaseAvailable(): boolean {\r\n  return getPool() !== null;\r\n}\r\n\r\n/**\r\n * Upsert Scattering metrics\r\n * - Updates the \"current\" snapshot with latest data\r\n * - Appends to history for trend analysis\r\n */\r\nexport async function upsertScatteringMetrics(\r\n  metrics: ScatteringFacilitatorMetrics[]\r\n): Promise<void> {\r\n  if (metrics.length === 0) {\r\n    logger.debug('No Scattering metrics to upsert');\r\n    return;\r\n  }\r\n\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      await upsertScatteringToDb(metrics);\r\n      return;\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to upsert Scattering metrics to database' });\r\n      throw error;\r\n    }\r\n  }\r\n\r\n  // Log summary even without DB\r\n  const totalVolume = metrics.reduce((sum, m) => sum + m.volumeUsd3d, 0);\r\n  const totalTxns = metrics.reduce((sum, m) => sum + m.txCount3d, 0);\r\n\r\n  logger.warn({\r\n    facilitatorCount: metrics.length,\r\n    totalVolume3d: `$${formatNumber(totalVolume)}`,\r\n    totalTxns3d: formatNumber(totalTxns),\r\n    msg: 'Database not available, Scattering metrics not persisted',\r\n  });\r\n}\r\n\r\n/**\r\n * Load all current Scattering metrics\r\n */\r\nexport async function loadAllScatteringMetrics(): Promise<ScatteringFacilitatorMetrics[]> {\r\n  const db = getPool();\r\n  if (db) {\r\n    try {\r\n      const metrics = await loadScatteringFromDb();\r\n      return Object.values(metrics);\r\n    } catch (error) {\r\n      logger.error({ error, msg: 'Failed to load Scattering metrics from database' });\r\n      return [];\r\n    }\r\n  }\r\n  return [];\r\n}\r\n\r\n/**\r\n * Get Scattering metrics for a specific facilitator\r\n */\r\nexport async function getScatteringMetricsForFacilitator(\r\n  facilitatorId: string\r\n): Promise<ScatteringFacilitatorMetrics | null> {\r\n  const db = getPool();\r\n  if (!db) return null;\r\n\r\n  try {\r\n    const result = await db.query(`\r\n      SELECT * FROM smf_scattering_metrics\r\n      WHERE facilitator_id = $1\r\n      ORDER BY fetched_at DESC\r\n      LIMIT 1\r\n    `, [facilitatorId]);\r\n\r\n    if (result.rows.length === 0) return null;\r\n    return mapDbRowToScattering(result.rows[0]);\r\n  } catch (error) {\r\n    logger.error({ error, facilitatorId, msg: 'Failed to get Scattering metrics' });\r\n    return null;\r\n  }\r\n}\r\n\r\n/**\r\n * Get Scattering metrics for multiple facilitators\r\n */\r\nexport async function getScatteringMetricsForFacilitators(\r\n  facilitatorIds: string[]\r\n): Promise<Map<string, ScatteringFacilitatorMetrics | null>> {\r\n  const result = new Map<string, ScatteringFacilitatorMetrics | null>();\r\n  \r\n  const db = getPool();\r\n  if (!db) {\r\n    for (const id of facilitatorIds) {\r\n      result.set(id, null);\r\n    }\r\n    return result;\r\n  }\r\n\r\n  try {\r\n    const metrics = await loadScatteringFromDb();\r\n    for (const id of facilitatorIds) {\r\n      result.set(id, metrics[id] ?? null);\r\n    }\r\n    return result;\r\n  } catch (error) {\r\n    logger.error({ error, msg: 'Failed to get Scattering metrics for facilitators' });\r\n    for (const id of facilitatorIds) {\r\n      result.set(id, null);\r\n    }\r\n    return result;\r\n  }\r\n}\r\n\r\n/**\r\n * Get historical snapshots for trend analysis\r\n */\r\nexport async function getScatteringHistory(\r\n  limit: number = 10\r\n): Promise<{ fetchedAt: string; metrics: ScatteringFacilitatorMetrics[] }[]> {\r\n  const db = getPool();\r\n  if (!db) return [];\r\n\r\n  try {\r\n    // Get distinct snapshots\r\n    const snapshotsResult = await db.query(`\r\n      SELECT DISTINCT snapshot_id, fetched_at \r\n      FROM smf_scattering_history\r\n      ORDER BY fetched_at DESC\r\n      LIMIT $1\r\n    `, [limit]);\r\n\r\n    const history: { fetchedAt: string; metrics: ScatteringFacilitatorMetrics[] }[] = [];\r\n\r\n    for (const snapshot of snapshotsResult.rows) {\r\n      const metricsResult = await db.query(`\r\n        SELECT * FROM smf_scattering_history\r\n        WHERE snapshot_id = $1\r\n      `, [snapshot.snapshot_id]);\r\n\r\n      history.push({\r\n        fetchedAt: snapshot.fetched_at?.toISOString() || snapshot.fetched_at,\r\n        metrics: metricsResult.rows.map(mapDbRowToScattering),\r\n      });\r\n    }\r\n\r\n    return history;\r\n  } catch (error) {\r\n    logger.error({ error, msg: 'Failed to get Scattering history' });\r\n    return [];\r\n  }\r\n}\r\n\r\n/**\r\n * Get historical metrics for a specific facilitator\r\n */\r\nexport async function getFacilitatorVolumeHistory(\r\n  facilitatorId: string,\r\n  limit: number = 10\r\n): Promise<ScatteringFacilitatorMetrics[]> {\r\n  const db = getPool();\r\n  if (!db) return [];\r\n\r\n  try {\r\n    const result = await db.query(`\r\n      SELECT * FROM smf_scattering_history\r\n      WHERE facilitator_id = $1\r\n      ORDER BY fetched_at DESC\r\n      LIMIT $2\r\n    `, [facilitatorId, limit]);\r\n\r\n    return result.rows.map(mapDbRowToScattering);\r\n  } catch (error) {\r\n    logger.error({ error, facilitatorId, msg: 'Failed to get volume history' });\r\n    return [];\r\n  }\r\n}\r\n\r\n// =============================================================================\r\n// ANALYSIS HELPERS\r\n// =============================================================================\r\n\r\n/**\r\n * Get top facilitators by 3-day volume\r\n */\r\nexport async function getTopFacilitatorsByVolume(\r\n  limit: number = 10\r\n): Promise<ScatteringFacilitatorMetrics[]> {\r\n  const metrics = await loadAllScatteringMetrics();\r\n  \r\n  return metrics\r\n    .sort((a, b) => b.volumeUsd3d - a.volumeUsd3d)\r\n    .slice(0, limit);\r\n}\r\n\r\n/**\r\n * Get top facilitators by 3-day transaction count\r\n */\r\nexport async function getTopFacilitatorsByTxCount(\r\n  limit: number = 10\r\n): Promise<ScatteringFacilitatorMetrics[]> {\r\n  const metrics = await loadAllScatteringMetrics();\r\n  \r\n  return metrics\r\n    .sort((a, b) => b.txCount3d - a.txCount3d)\r\n    .slice(0, limit);\r\n}\r\n\r\n/**\r\n * Get facilitators with positive volume growth\r\n */\r\nexport async function getGrowingFacilitators(): Promise<ScatteringFacilitatorMetrics[]> {\r\n  const metrics = await loadAllScatteringMetrics();\r\n  \r\n  return metrics\r\n    .filter((m) => m.volumeChangeRate !== undefined && m.volumeChangeRate > 0)\r\n    .sort((a, b) => (b.volumeChangeRate ?? 0) - (a.volumeChangeRate ?? 0));\r\n}\r\n\r\n/**\r\n * Calculate activity score for a facilitator (0-1 scale)\r\n * Used by SMF scoring to evaluate facilitator health\r\n */\r\nexport function computeActivityScore(metrics: ScatteringFacilitatorMetrics): number {\r\n  // Weights for different factors\r\n  const VOLUME_WEIGHT = 0.3;\r\n  const TX_WEIGHT = 0.3;\r\n  const BUYERS_WEIGHT = 0.2;\r\n  const SELLERS_WEIGHT = 0.1;\r\n  const GROWTH_WEIGHT = 0.1;\r\n\r\n  // Reference values (approximate top-tier facilitator numbers)\r\n  const MAX_VOLUME = 200_000; // $200K 3d volume\r\n  const MAX_TX = 3_000_000;   // 3M txns\r\n  const MAX_BUYERS = 15_000;  // 15K unique buyers\r\n  const MAX_SELLERS = 1_000;  // 1K unique sellers\r\n\r\n  // Normalize each factor to 0-1\r\n  const volumeScore = Math.min(metrics.volumeUsd3d / MAX_VOLUME, 1);\r\n  const txScore = Math.min(metrics.txCount3d / MAX_TX, 1);\r\n  const buyersScore = Math.min(metrics.uniqueBuyers3d / MAX_BUYERS, 1);\r\n  const sellersScore = Math.min(metrics.uniqueSellers3d / MAX_SELLERS, 1);\r\n\r\n  // Growth bonus (positive growth adds to score, negative subtracts)\r\n  let growthScore = 0.5; // neutral\r\n  if (metrics.volumeChangeRate !== undefined) {\r\n    // Clamp growth between -100% and +100%\r\n    const clampedGrowth = Math.max(-100, Math.min(100, metrics.volumeChangeRate));\r\n    growthScore = (clampedGrowth + 100) / 200; // normalize to 0-1\r\n  }\r\n\r\n  // Calculate weighted score\r\n  const score = \r\n    volumeScore * VOLUME_WEIGHT +\r\n    txScore * TX_WEIGHT +\r\n    buyersScore * BUYERS_WEIGHT +\r\n    sellersScore * SELLERS_WEIGHT +\r\n    growthScore * GROWTH_WEIGHT;\r\n\r\n  return Math.min(Math.max(score, 0), 1); // clamp to 0-1\r\n}\r\n\r\n// =============================================================================\r\n// CLEANUP\r\n// =============================================================================\r\n\r\n/**\r\n * Clean up old history snapshots\r\n */\r\nexport async function cleanupOldSnapshots(keepDays: number = 30): Promise<number> {\r\n  const db = getPool();\r\n  if (!db) return 0;\r\n\r\n  try {\r\n    const result = await db.query(`\r\n      DELETE FROM smf_scattering_history\r\n      WHERE fetched_at < NOW() - INTERVAL '${keepDays} days'\r\n    `);\r\n\r\n    const removed = result.rowCount || 0;\r\n    if (removed > 0) {\r\n      logger.info({ removed, keepDays, msg: 'Old Scattering snapshots cleaned up' });\r\n    }\r\n\r\n    return removed;\r\n  } catch (error) {\r\n    logger.error({ error, msg: 'Failed to cleanup old snapshots' });\r\n    return 0;\r\n  }\r\n}\r\n\r\n// =============================================================================\r\n// UTILITY\r\n// =============================================================================\r\n\r\n/**\r\n * Format number for logging (e.g., 137535 -> \"137.5K\")\r\n */\r\nfunction formatNumber(num: number): string {\r\n  if (num >= 1_000_000) {\r\n    return `${(num / 1_000_000).toFixed(1)}M`;\r\n  }\r\n  if (num >= 1_000) {\r\n    return `${(num / 1_000).toFixed(1)}K`;\r\n  }\r\n  return num.toFixed(2);\r\n}\r\n"],"names":[],"mappings":"8CA6BA,IAAA,EAAA,EAAA,CAAA,CAAA,OAOA,EAAA,EAAA,CAAA,CAAA,yCAEA,IAAM,EAAS,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,CAAE,UAAW,2BAA4B,GAMjE,EAAoB,KAExB,SAAS,IACP,GAAI,EAAM,OAAO,EAEjB,IAAM,EAAc,QAAQ,GAAG,CAAC,YAAY,QAC5C,AAAI,AAAC,GAAgB,EAAY,UAAb,AAAuB,CAAC,iBAI5C,CAJ8D,CAIvD,IAAI,EAAA,IAAI,CAAC,CACd,iBAAkB,EAClB,IAAK,EACL,kBAAmB,IACnB,wBAAyB,GAC3B,GARS,IAWX,CASA,eAAe,EAAkB,CAAiC,EAChE,IAAM,EAAK,IACX,GAAI,CAAC,GAAyB,IAAnB,EAAQ,MAAM,CAAQ,OAEjC,IAAM,EAAS,MAAM,EAAG,OAAO,GAC/B,GAAI,CAGF,IAAK,IAAM,KAFX,MAAM,EAAO,KAAK,CAAC,SAEH,GACd,KADuB,CACjB,EAAO,KAAK,CAAC,CAAC;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;MAwCpB,CAAC,CAAE,CACD,EAAE,IAAI,CACN,EAAE,aAAa,CACf,EAAE,WAAW,EAAI,KACjB,EAAE,QAAQ,EAAI,KACd,EAAE,OAAO,EAAI,KACb,EAAE,SAAS,CACX,EAAE,aAAa,CACf,EAAE,eAAe,CACjB,EAAE,aAAa,CACf,EAAE,WAAW,CACb,EAAE,YAAY,CACd,EAAE,YAAY,CACd,EAAE,QAAQ,CACV,EAAE,QAAQ,CACV,EAAE,QAAQ,CACV,EAAE,QAAQ,CACV,EAAE,SAAS,CACX,EAAE,YAAY,EAAI,KAClB,EAAE,YAAY,EAAI,KAClB,EAAE,YAAY,EAAI,KAClB,EAAE,YAAY,EAAI,KAClB,EAAE,YAAY,EAAI,KAClB,EAAE,OAAO,CAAG,KAAK,SAAS,CAAC,EAAE,OAAO,EAAI,KACxC,EAAE,SAAS,CACZ,CAGH,OAAM,EAAO,KAAK,CAAC,UAEnB,EAAO,IAAI,CAAC,CACV,MAAO,EAAQ,MAAM,CACrB,cAAe,CAAO,CAAC,EAAE,EAAE,cAC3B,UAAW,CAAO,CAAC,EAAE,EAAE,UACvB,IAAK,0CACP,EACF,CAAE,MAAO,EAAO,CAEd,MADA,MAAM,EAAO,KAAK,CAAC,YACb,CACR,QAAU,CACR,EAAO,OAAO,EAChB,CACF,CAKA,eAAe,EACb,CAAsB,CACtB,CAA2C,EAE3C,IAAM,EAAK,IACX,GAAI,CAAC,EAAI,MAAO,EAAE,CAElB,IAAI,EAAQ,CAAC;;;EAGb,CAAC,CACK,EAAgB,EAAE,CACpB,EAAa,EAiBjB,OAfI,IACF,GAAS,CAAC,OADO,gBACgB,EAAE,EAAA,CAAY,CAC/C,EAAO,IAAI,CAAC,GACZ,KAGE,IACF,GAAS,CAAC,GADG,eACe,EAAE,EAAA,CAAY,CAC1C,EAAO,IAAI,CAAC,GACZ,KAGF,GAAS,8CAGF,CADQ,MAAM,EAAG,KAAK,CAAC,EAAO,EAAA,EACvB,IAAI,CAAC,GAAG,CAAC,EACzB,CAKA,SAAS,EAAkB,CAAQ,EACjC,MAAO,CACL,KAAM,EAAI,IAAI,EAAI,qBAClB,cAAe,EAAI,cAAc,CACjC,YAAa,EAAI,YAAY,EAAI,OACjC,SAAU,EAAI,SAAS,OAAI,EAC3B,QAAS,EAAI,OAAO,OAAI,EACxB,UAAW,EAAI,SAAS,CACxB,cAAe,EAAI,cAAc,CACjC,gBAAiB,EAAI,iBAAiB,EAAE,eAAiB,EAAI,iBAAiB,CAC9E,cAAe,EAAI,eAAe,EAAE,eAAiB,EAAI,eAAe,CACxE,YAAa,EAAI,WAAW,CAC5B,aAAc,EAAI,aAAa,CAC/B,aAAc,EAAI,aAAa,CAC/B,SAAU,EAAI,SAAS,CACvB,SAAU,EAAI,SAAS,CACvB,SAAU,EAAI,SAAS,CACvB,SAAU,EAAI,SAAS,CACvB,UAAW,WAAW,EAAI,UAAU,GAAK,EACzC,aAAc,EAAI,cAAc,CAAG,WAAW,EAAI,cAAc,OAAI,EACpE,aAAc,EAAI,cAAc,CAAG,WAAW,EAAI,cAAc,OAAI,EACpE,aAAc,EAAI,cAAc,CAAG,WAAW,EAAI,cAAc,OAAI,EACpE,aAAc,EAAI,cAAc,CAAG,WAAW,EAAI,cAAc,EAAI,OACpE,aAAc,EAAI,cAAc,CAAG,WAAW,EAAI,cAAc,OAAI,EACpE,QAAS,EAAI,OAAO,OAAI,EACxB,UAAW,EAAI,UAAU,EAAE,eAAiB,EAAI,UAAU,AAC5D,CACF,CAKA,eAAe,EAAkB,CAA2B,EAC1D,IAAM,EAAK,IACX,GAAI,CAAC,EAAI,OAGT,IAAM,EAAY,EAAQ,SAAS,EAAI,EAAQ,SAAS,CAAC,MAAM,CAAG,EAAI,EAAQ,SAAS,CAAG,KACpF,EAAU,EAAQ,OAAO,EAAI,EAAQ,OAAO,CAAC,MAAM,CAAG,EAAI,EAAQ,OAAO,CAAG,IAGlF,CAAiC,IAA7B,CAAkC,CAA1B,gBAAgB,EAAW,GAAc,GASrD,MAT8D,AASxD,CAT8C,CAS3C,KAAK,CAAC,CAAC;;;;;;;;;;;;;;;;;;;;;EAqBhB,CAAC,CAAE,CACD,EAAQ,aAAa,CACrB,EAAQ,SAAS,CACjB,EAAQ,gBAAgB,CACxB,EAAQ,cAAc,CACtB,EAAQ,aAAa,CACrB,EAAQ,gBAAgB,CACxB,EAAQ,eAAe,EAAI,KAC3B,EAAQ,eAAe,EAAI,KAC3B,EAAQ,eAAe,EAAI,KAC3B,KAAK,SAAS,CAAC,EAAQ,UAAU,EACjC,EACA,EACA,EAAQ,SAAS,CAClB,EAED,EAAO,IAAI,CAAC,CACV,cAAe,EAAQ,aAAa,CACpC,UAAW,EAAQ,SAAS,CAC5B,iBAAkB,EAAQ,gBAAgB,CAC1C,IAAK,0CACP,IAlDE,EAAO,KAAK,CAAC,CACX,cAAe,EAAQ,aAAa,CACpC,UAAW,EAAQ,SAAS,CAC5B,IAAK,+BACP,EA+CJ,CAKA,eAAe,IACb,IAAM,EAAK,IACX,GAAI,CAAC,EAAI,MAAO,CAAC,EAEjB,IAAM,EAAS,MAAM,EAAG,KAAK,CAAC,CAAC;;;EAG/B,CAAC,EAEK,EAAgD,CAAC,EACvD,IAAK,IAAM,KAAO,EAAO,IAAI,CAAE,AAE7B,CAAS,CADG,AACF,CADE,EAAG,EAAI,cAAc,CAAC,CAAC,EAAE,EAAI,SAAS,CAAA,CAAE,CACtC,CAAG,CACf,cAAe,EAAI,cAAc,CACjC,UAAW,EAAI,SAAS,CACxB,iBAAkB,SAAS,EAAI,iBAAiB,GAAK,EACrD,eAAgB,SAAS,EAAI,eAAe,GAAK,EACjD,cAAe,SAAS,EAAI,cAAc,GAAK,EAC/C,iBAAkB,WAAW,EAAI,kBAAkB,GAAK,EACxD,gBAAiB,EAAI,kBAAkB,CAAG,WAAW,EAAI,kBAAkB,OAAI,EAC/E,gBAAiB,EAAI,kBAAkB,CAAG,WAAW,EAAI,kBAAkB,OAAI,EAC/E,gBAAiB,EAAI,kBAAkB,CAAG,WAAW,EAAI,kBAAkB,EAAI,OAC/E,WAAY,EAAI,WAAW,EAAI,EAAE,CACjC,UAAW,EAAI,UAAU,EAAE,eAAiB,EAAI,UAAU,CAC1D,QAAS,EAAI,QAAQ,EAAE,eAAiB,EAAI,QAAQ,CACpD,UAAW,EAAI,UAAU,EAAE,eAAiB,EAAI,UAAU,AAC5D,EAGF,OAAO,CACT,CAmCO,eAAe,EACpB,CAAiC,EAEjC,GAAuB,IAAnB,EAAQ,MAAM,CAAQ,YACxB,EAAO,KAAK,CAAC,wBAKf,GADW,CACP,GACF,CADM,EACF,CACF,MAAM,EAAkB,GACxB,MACF,CAAE,MAAO,EAAO,CAEd,MADA,EAAO,KAAK,CAAC,OAAE,EAAO,IAAK,sCAAuC,GAC5D,CACR,CAIF,EAAO,IAAI,CAAC,CACV,MAAO,EAAQ,MAAM,CACrB,IAAK,+CACP,EACF,CAKO,eAAe,IAEpB,GADW,CACP,GACF,CADM,EACF,CACF,OAAO,MAAM,GACf,CAAE,MAAO,EAAO,CACd,EAAO,KAAK,CAAC,OAAE,EAAO,IAAK,wCAAyC,EAEtE,CAEF,MAAO,CAAC,CACV,CAKO,eAAe,EAAyB,CAA2B,EAExE,GADW,CACP,GACF,CADM,EACF,CACF,MAAM,EAAkB,GACxB,MACF,CAAE,MAAO,EAAO,CAEd,MADA,EAAO,KAAK,CAAC,OAAE,EAAO,IAAK,sCAAuC,GAC5D,CACR,CAGF,EAAO,IAAI,CAAC,CACV,cAAe,EAAQ,aAAa,CACpC,IAAK,+CACP,EACF,CAKO,eAAe,EAA2B,CAA+B,EAC9E,IAAK,IAAM,KAAW,EACpB,MAAM,EAAyB,AADA,EAGnC,CASO,eAAe,EACpB,CAAqB,CACrB,CAA2C,EAG3C,GADW,CACP,GACF,CADM,EACF,CACF,OAAO,MAAM,EAAkB,EAAe,EAChD,CAAE,MAAO,EAAO,CACd,EAAO,KAAK,CAAC,CAAE,QAAO,IAAK,uCAAwC,EAErE,CAEF,MAAO,EAAE,AACX,CAKO,eAAe,EACpB,CAAqB,CACrB,CAA0C,EAI1C,MAAO,CAFW,MAAM,GAAA,CAER,CADJ,AACK,CADL,EAAG,EAAc,CAAC,EAAE,EAAA,CAAW,CACtB,EAAI,IAC3B,kNC7bA,IAAA,EAAA,EAAA,CAAA,CAAA,OAEA,EAAA,EAAA,CAAA,CAAA,yCAEA,IAAM,EAAS,CAAA,EAAA,EAAA,YAAA,AAAY,EAAC,CAAE,UAAW,0BAA2B,GAMhE,EAAoB,KAExB,SAAS,IACP,GAAI,EAAM,OAAO,EAEjB,IAAM,EAAc,QAAQ,GAAG,CAAC,YAAY,QAC5C,AAAI,AAAC,GAAgB,EAAY,UAAU,AAAvB,CAAwB,iBAI5C,CAJ8D,CAIvD,IAAI,EAAA,IAAI,CAAC,CACd,iBAAkB,EAClB,IAAK,EACL,kBAAmB,IACnB,wBAAyB,GAC3B,GARS,IAWX,CASA,eAAe,EAAqB,CAAuC,EACzE,IAAM,EAAK,IACX,GAAI,CAAC,GAAyB,IAAnB,EAAQ,MAAM,CAAQ,OAEjC,IAAM,EAAS,MAAM,EAAG,OAAO,GACzB,EAAY,IAAI,OAAO,WAAW,GAClC,EAAa,OAAO,UAAU,CAAG,OAAO,UAAU,GAAK,CAAA,EAAG,KAAK,GAAG,GAAG,CAAC,EAAE,KAAK,MAAM,GAAG,QAAQ,CAAC,IAAI,KAAK,CAAC,GAAA,CAAI,CAEnH,GAAI,CAGF,IAAK,IAAM,KAFX,MAAM,EAAO,KAAK,CAAC,SAEH,GAEd,KAFuB,CAEjB,EAAO,KAAK,CAAC,CAAC;;;;;;;;;;;;;;;;;;;MAmBpB,CAAC,CAAE,CACD,EAAE,aAAa,CACf,EAAE,MAAM,CACR,EAAE,WAAW,CACb,EAAE,SAAS,CACX,EAAE,cAAc,CAChB,EAAE,eAAe,CACjB,EAAE,gBAAgB,CAClB,KAAK,SAAS,CAAC,EAAE,MAAM,EACvB,EAAE,gBAAgB,EAAI,KACtB,EAAE,YAAY,EAAI,KAClB,EACD,EAGD,MAAM,EAAO,KAAK,CAAC,CAAC;;;;;;;MAOpB,CAAC,CAAE,CACD,EACA,EAAE,aAAa,CACf,EAAE,MAAM,CACR,EAAE,WAAW,CACb,EAAE,SAAS,CACX,EAAE,cAAc,CAChB,EAAE,eAAe,CACjB,EAAE,gBAAgB,CAClB,KAAK,SAAS,CAAC,EAAE,MAAM,EACvB,EAAE,gBAAgB,EAAI,KACtB,EAAE,YAAY,EAAI,KAClB,EACD,CAGH,OAAM,EAAO,KAAK,CAAC,UAGnB,IAAM,EAAc,EAAQ,MAAM,CAAC,CAAC,EAAK,IAAM,EAAM,EAAE,WAAW,CAAE,GAC9D,EAAY,EAAQ,MAAM,CAAC,CAAC,EAAK,IAAM,EAAM,EAAE,SAAS,CAAE,GAEhE,EAAO,IAAI,CAAC,CACV,iBAAkB,EAAQ,MAAM,CAChC,cAAe,CAAC,CAAC,EAAE,EAAa,GAAA,CAAc,CAC9C,YAAa,EAAa,GAC1B,IAAK,yCACP,EACF,CAAE,MAAO,EAAO,CAEd,MADA,MAAM,EAAO,KAAK,CAAC,YACb,CACR,QAAU,CACR,EAAO,OAAO,EAChB,CACF,CAKA,eAAe,IACb,IAAM,EAAK,IACX,GAAI,CAAC,EAAI,MAAO,CAAC,EAEjB,IAAM,EAAS,MAAM,EAAG,KAAK,CAAC,CAAC;;;EAG/B,CAAC,EAEK,EAAwD,CAAC,EAC/D,IAAK,IAAM,KAAO,EAAO,IAAI,CAAE,AAC7B,CAAO,CAAC,EAAI,cAAc,CAAC,CAAG,EAAqB,GAGrD,OAAO,CACT,CAKA,SAAS,EAAqB,CAAQ,EACpC,MAAO,CACL,cAAe,EAAI,cAAc,CACjC,OAAQ,EAAI,MAAM,EAAI,KACtB,YAAa,WAAW,EAAI,aAAa,GAAK,EAC9C,UAAW,SAAS,EAAI,WAAW,GAAK,EACxC,eAAgB,EAAI,gBAAgB,EAAI,EACxC,gBAAiB,EAAI,iBAAiB,EAAI,EAC1C,iBAAkB,WAAW,EAAI,mBAAmB,GAAK,EACzD,OAAQ,EAAI,MAAM,EAAI,EAAE,CACxB,iBAAkB,EAAI,kBAAkB,CAAG,WAAW,EAAI,kBAAkB,OAAI,EAChF,aAAc,EAAI,cAAc,CAAG,WAAW,EAAI,cAAc,EAAI,OACpE,UAAW,EAAI,UAAU,EAAE,eAAiB,EAAI,UAAU,AAC5D,CACF,CAkBO,eAAe,EACpB,CAAuC,EAEvC,GAAuB,IAAnB,EAAQ,MAAM,CAAQ,YACxB,EAAO,KAAK,CAAC,mCAKf,GADW,CACP,GACF,CADM,EACF,CACF,MAAM,EAAqB,GAC3B,MACF,CAAE,MAAO,EAAO,CAEd,MADA,EAAO,KAAK,CAAC,OAAE,EAAO,IAAK,iDAAkD,GACvE,CACR,CAIF,IAAM,EAAc,EAAQ,MAAM,CAAC,CAAC,EAAK,IAAM,EAAM,EAAE,WAAW,CAAE,GAC9D,EAAY,EAAQ,MAAM,CAAC,CAAC,EAAK,IAAM,EAAM,EAAE,SAAS,CAAE,GAEhE,EAAO,IAAI,CAAC,CACV,iBAAkB,EAAQ,MAAM,CAChC,cAAe,CAAC,CAAC,EAAE,EAAa,GAAA,CAAc,CAC9C,YAAa,EAAa,GAC1B,IAAK,0DACP,EACF,CAsBO,eAAe,EACpB,CAAqB,EAErB,IAAM,EAAK,IACX,GAAI,CAAC,EAAI,OAAO,KAEhB,GAAI,CACF,IAAM,EAAS,MAAM,EAAG,KAAK,CAAC,CAAC;;;;;IAK/B,CAAC,CAAE,CAAC,EAAc,EAElB,GAA2B,IAAvB,EAAO,IAAI,CAAC,MAAM,CAAQ,OAAO,KACrC,OAAO,EAAqB,EAAO,IAAI,CAAC,EAAE,CAC5C,CAAE,MAAO,EAAO,CAEd,OADA,EAAO,KAAK,CAAC,OAAE,gBAAO,EAAe,IAAK,kCAAmC,GACtE,IACT,CACF,CAKO,eAAe,EACpB,CAAwB,EAExB,IAAM,EAAS,IAAI,IAGnB,GAAI,CADO,AACN,IAAI,CACP,IAAK,IAAM,KAAM,EACf,EAAO,GAAG,CAAC,EAAI,KADgB,CAGjC,OAAO,CACT,CAEA,GAAI,CACF,IAAM,EAAU,MAAM,IACtB,IAAK,IAAM,KAAM,EACf,EAAO,GAAG,CAAC,EAAI,CAAO,CAAC,EAAG,CADK,CACD,MAEhC,OAAO,CACT,CAAE,MAAO,EAAO,CAEd,IAAK,IAAM,KADX,EAAO,KAAK,CAAC,OAAE,EAAO,IAAK,mDAAoD,GAC9D,GACf,EAAO,GAAG,CAAC,EAAI,IADgB,EAGjC,OAAO,CACT,CACF,CA+GO,SAAS,EAAqB,CAAqC,EAexE,IAAM,EAAc,KAAK,GAAG,CAAC,EAAQ,WAAW,CAN7B,EAMgC,EAAY,GACzD,EAAU,AAPY,KAOP,GAAG,CAAC,EAAQ,OAPa,EAOJ,CAN3B,EAM8B,EAAQ,GAC/C,EAAc,EAPQ,GAOH,GAAG,CAAC,EAAQ,CAPC,aAOa,CANhC,EAMmC,GAAY,GANtC,AAOtB,EAAe,KAAK,GAAG,CAAC,EAAQ,OAPU,QAOK,CANjC,EAMoC,EAAa,GAGjE,AATwB,EASV,KAAK,GACU,IAA7B,EAAQ,CADqB,GATe,CAUJ,WAAhB,GAG1B,EAAc,AAAC,CADO,KAAK,GAAG,CAAC,CAAC,IAAK,KAAK,GAAG,CAAC,IAAK,EAAQ,gBAAgB,GAC5C,GAAA,CAAG,CAAI,GAAA,EAIxC,CAJ6C,GAIvC,EA3BgB,GA4BpB,EA3BgB,GA4BhB,EA3BoB,GA4BpB,CAP8D,CApBzC,EAyBP,CACJ,AAEV,EA3BoB,GA4BpB,EAEF,EAJgB,KAIT,CAHU,IACD,AAEJ,GAAG,CAAC,KAAK,GAAG,CAAC,EAAO,GAAI,EACtC,CAsCA,CAvC0C,QAuCjC,EAAa,CAAW,IAvCwB,KAwCvD,AAAI,GAAO,IACF,CAAA,EAAG,CAAC,EAAM,CADG,EACH,CAAS,CAAE,OAAO,CAAC,GAAG,CAAC,CAAC,CAEvC,GAAO,IACF,CAAA,EADS,AACN,CAAC,EAAM,GAAA,CAAK,CAAE,OAAO,CAAC,GAAG,CAAC,CAAC,CAEhC,EAAI,OAAO,CAAC,EACrB"}